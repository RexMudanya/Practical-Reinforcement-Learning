{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# gym environment\n",
    "\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-v0\")\n",
    "env = JoypadSpace(env, RIGHT_ONLY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100000\u001B[39m):\n\u001B[0;32m----> 7\u001B[0m     \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m     10\u001B[0m         state \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset()\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/gym/core.py:240\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self, mode, **kwargs)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/gym/core.py:240\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self, mode, **kwargs)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/nes_py/nes_env.py:379\u001B[0m, in \u001B[0;36mNESEnv.render\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m    373\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mviewer \u001B[38;5;241m=\u001B[39m ImageViewer(\n\u001B[1;32m    374\u001B[0m             caption\u001B[38;5;241m=\u001B[39mcaption,\n\u001B[1;32m    375\u001B[0m             height\u001B[38;5;241m=\u001B[39mSCREEN_HEIGHT,\n\u001B[1;32m    376\u001B[0m             width\u001B[38;5;241m=\u001B[39mSCREEN_WIDTH,\n\u001B[1;32m    377\u001B[0m         )\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;66;03m# show the screen on the image viewer\u001B[39;00m\n\u001B[0;32m--> 379\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mviewer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscreen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscreen\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/nes_py/_image_viewer.py:148\u001B[0m, in \u001B[0;36mImageViewer.show\u001B[0;34m(self, frame)\u001B[0m\n\u001B[1;32m    140\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyglet\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mImageData(\n\u001B[1;32m    141\u001B[0m     frame\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    142\u001B[0m     frame\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    145\u001B[0m     pitch\u001B[38;5;241m=\u001B[39mframe\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3\u001B[39m\n\u001B[1;32m    146\u001B[0m )\n\u001B[1;32m    147\u001B[0m \u001B[38;5;66;03m# send the image to the window\u001B[39;00m\n\u001B[0;32m--> 148\u001B[0m \u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_window\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_window\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_window\u001B[38;5;241m.\u001B[39mflip()\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/pyglet/image/__init__.py:903\u001B[0m, in \u001B[0;36mImageData.blit\u001B[0;34m(self, x, y, z, width, height)\u001B[0m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mblit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, z\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, width\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, height\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 903\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_texture\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mblit(x, y, z, width, height)\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/pyglet/image/__init__.py:834\u001B[0m, in \u001B[0;36mImageData.get_texture\u001B[0;34m(self, rectangle, force_rectangle)\u001B[0m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_texture\u001B[39m(\u001B[38;5;28mself\u001B[39m, rectangle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, force_rectangle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    832\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_texture \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m    833\u001B[0m             (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_texture\u001B[38;5;241m.\u001B[39m_is_rectangle \u001B[38;5;129;01mand\u001B[39;00m force_rectangle)):\n\u001B[0;32m--> 834\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_texture \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_texture\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTexture\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrectangle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_rectangle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_texture\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/pyglet/image/__init__.py:826\u001B[0m, in \u001B[0;36mImageData.create_texture\u001B[0;34m(self, cls, rectangle, force_rectangle)\u001B[0m\n\u001B[1;32m    823\u001B[0m     texture\u001B[38;5;241m.\u001B[39manchor_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manchor_x\n\u001B[1;32m    824\u001B[0m     texture\u001B[38;5;241m.\u001B[39manchor_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manchor_y\n\u001B[0;32m--> 826\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblit_to_texture\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtexture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manchor_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manchor_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m texture\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/pyglet/image/__init__.py:976\u001B[0m, in \u001B[0;36mImageData.blit_to_texture\u001B[0;34m(self, target, level, x, y, z, internalformat)\u001B[0m\n\u001B[1;32m    974\u001B[0m glPushClientAttrib(GL_CLIENT_PIXEL_STORE_BIT)\n\u001B[1;32m    975\u001B[0m glPixelStorei(GL_UNPACK_ALIGNMENT, alignment)\n\u001B[0;32m--> 976\u001B[0m \u001B[43mglPixelStorei\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGL_UNPACK_ROW_LENGTH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_region_unpack()\n\u001B[1;32m    979\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;241m==\u001B[39m GL_TEXTURE_3D:\n",
      "File \u001B[0;32m~/Desktop/Projects/study/udemy/AI/PracticalReinforcementLearning/venv/lib/python3.8/site-packages/pyglet/gl/lib.py:87\u001B[0m, in \u001B[0;36merrcheck\u001B[0;34m(result, func, arguments)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mGLException\u001B[39;00m(\u001B[38;5;167;01mException\u001B[39;00m):\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merrcheck\u001B[39m(result, func, arguments):\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _debug_gl_trace:\n\u001B[1;32m     89\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# take random actions\n",
    "\n",
    "total_reward = 0\n",
    "done = True\n",
    "\n",
    "for step in range(100000):\n",
    "    env.render()\n",
    "\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    print(info)\n",
    "    total_reward += reward\n",
    "    clear_output(wait=True)\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # agent variables\n",
    "        self.state_space = state_size\n",
    "        self.action_space = action_size\n",
    "        self.memory = deque(maxlen=5000)\n",
    "\n",
    "        # exploration vs exploitation\n",
    "        self.epsilon = 1\n",
    "        self.max_exploration = 1\n",
    "        self.min_epsilon = 0.01\n",
    "        self.decay_epsilon = .0001\n",
    "\n",
    "        # NN\n",
    "        self.main_network = self.build_network()\n",
    "        self.target_network = self.build_network()\n",
    "        self.update_target_network()  # set weights of main net to target network\n",
    "\n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, (4,4), strides=4, padding='same', input_shape=self.state_space))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(64, (4,4), strides=2, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "\n",
    "        model.add(Dense(self.action_space, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def update_target_network(self):\n",
    "        # avoid oscillation\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        # epsilon greedy if eps is large take random action else take prediction using main net\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.randint(self.action_space)  # env.action_space.sample\n",
    "\n",
    "        Q_value = self.main_network.predict(state)\n",
    "\n",
    "        return np.argmax(Q_value[0])\n",
    "\n",
    "    def update_epsilon(self, episode):\n",
    "        # decays epsilon\n",
    "        self.epsilon = self.min_epsilon + (self.max_exploration - self.min_epsilon) * np.exp(-self.decay_epsilon * episode)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}